{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save time and effort with pipeline automation\n",
    "\n",
    "#### In this example, we're particularly looking at d6tflow which is a tool to build easy, fast, and intuitive workflows. It is also used as a lightweight model to productionize ML models faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading postgres module without psycopg2 nor pg8000 installed. Will crash at runtime if postgres functionality is used.\n",
      "Loading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to d6tflow! For Q&A see https://github.com/d6t/d6tflow\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import d6tflow\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# helper function\n",
    "from helpers import deploy_least_rmse_model\n",
    "\n",
    "# Model training and evaluation libraries\n",
    "from surprise import Reader\n",
    "from surprise import NMF, SVDpp, SVD\n",
    "from surprise import Dataset\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Workflows\n",
    "\n",
    "##### In the below example, we'll be defining a workflow to read, pre-process, train ML models, and deploy the best model for a movie recommendation system. This is accomplished by creating small tasks for each of the stages involved in this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, we create a task to get data from a source. It can be anything, a Kafka stream, CSV file, database, and so on. In our example, we have a batch of data collected from a Kafka stream of logs whose data involve ratings of movies by users. To simplify the data collectin process, we have already collected the data from Kafka stream and have stored it in a CSV file which is read in the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datar\n",
    "class GetData(d6tflow.tasks.TaskCSVPandas):  # save dataframe as parquet\n",
    "    def run(self):\n",
    "        ratings_df = pd.read_csv(\"./data/kafka_ratings.txt\",header=None)\n",
    "        self.save(ratings_df) # quickly save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, we define a task to pre-process the data that is collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process Data\n",
    "@d6tflow.requires(GetData) # define dependency\n",
    "class PreProcess(d6tflow.tasks.TaskCSVPandas):  # save dataframe as parquet\n",
    "    def run(self):\n",
    "        ratings_df = self.input().load()\n",
    "        ratings_df.columns = [\"Timestamp\",\"User\",\"Log\"]\n",
    "        ratings_df[\"MovieName\"] = ratings_df[\"Log\"].apply(lambda x: x.split(\"/\")[2].split(\"=\")[0])\n",
    "        ratings_df[\"Rating\"] = ratings_df[\"Log\"].apply(lambda x: x.split(\"/\")[2].split(\"=\")[1])\n",
    "        ratings_df = ratings_df[[\"Timestamp\", \"User\", \"MovieName\", \"Rating\"]]\n",
    "        ratings_df = ratings_df.drop_duplicates(subset=['User', 'MovieName'],keep=\"last\")\n",
    "        ratings_df = ratings_df.sort_values(by=['Timestamp'])\n",
    "        self.save(ratings_df) # quickly save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The ML algorithm we are using for movie recommendation is called as [Collaborative filtering](https://developers.google.com/machine-learning/recommendation/collaborative/basics) which requires the user and item (in this case a movie) to be represented as a numerical ID. Hence, in the next task, we create IDs for movies and add them to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map movie names to a numerical id\n",
    "@d6tflow.requires(PreProcess) # define dependency\n",
    "class MapMovieNameToID(d6tflow.tasks.TaskCSVPandas):  # save dataframe as parquet\n",
    "    def def_movie_value():\n",
    "        return \"Not Present\"\n",
    "\n",
    "    def run(self):\n",
    "        ratings_df = self.input().load()\n",
    "        movie_id_dict = defaultdict(MapMovieNameToID.def_movie_value)\n",
    "        movie_list=ratings_df['MovieName'].unique()\n",
    "        for index in range(len(movie_list)):\n",
    "            movie_id_dict[movie_list[index]] = index\n",
    "        ratings_df['Item'] = ratings_df['MovieName'].apply(lambda x: movie_id_dict[x])\n",
    "        ratings_df_processed = ratings_df[['User','Item','Rating']]\n",
    "        self.save(ratings_df_processed) # quickly save dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once the pre-processing of the data is complete, we define the next task which is model training. Here, we are training multiple models ([Matrix Factorization-based algorithms](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)) such as [SVD (Singular Value Decomposition)](https://surprise.readthedocs.io/en/stable/matrix_factorization.html), [SVD++ (Singular Value Decomposition Plus Plus)](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp), and [NMF (Non-Negative Matrix Factorization)](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF). We save all of the models created, as well as evaluate the quality of the model through [RMSE (Root Mean Squared Error)](https://en.wikipedia.org/wiki/Root-mean-square_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map movie names to a numerical id\n",
    "@d6tflow.requires(MapMovieNameToID) # define dependency\n",
    "class ModelTrain(d6tflow.tasks.TaskCache):  # save model as pickle\n",
    "    model = d6tflow.Parameter(default='svd') # parameter for model selection\n",
    "\n",
    "    def run(self):\n",
    "        ratings_df_processed = self.input().load()\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        ratings_dataset = Dataset.load_from_df(ratings_df_processed[[\"User\", \"Item\", \"Rating\"]], reader)\n",
    "        ratings_trainset, ratings_testset = train_test_split(ratings_dataset, test_size=0.3, shuffle=False)\n",
    "\n",
    "        if self.model == 'nmf':\n",
    "            model = NMF()\n",
    "        elif self.model == 'svdpp':\n",
    "            model = SVDpp()\n",
    "        elif self.model == 'svd':\n",
    "            model = SVD()\n",
    "        else:\n",
    "            raise ValueError('invalid model selection')\n",
    "\n",
    "        model.fit(ratings_trainset)\n",
    "        self.save(model)\n",
    "        self.saveMeta({'rmse': model.test(ratings_testset)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preview the flow of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== Luigi Execution Preview ===== \n",
      "\n",
      "\n",
      "└─--[ModelTrain-{'model': 'svd'} (\u001b[94mPENDING\u001b[0m)]\n",
      "   └─--[MapMovieNameToID- (\u001b[92mCOMPLETE\u001b[0m)]\n",
      "      └─--[PreProcess- (\u001b[92mCOMPLETE\u001b[0m)]\n",
      "         └─--[GetData- (\u001b[92mCOMPLETE\u001b[0m)]\n",
      "\n",
      " ===== Luigi Execution Preview ===== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "d6tflow.preview(ModelTrain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the model flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MapMovieNameToID()\n",
      "* 1 ran successfully:\n",
      "    - 1 ModelTrain(model=svd)\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MapMovieNameToID()\n",
      "* 1 ran successfully:\n",
      "    - 1 ModelTrain(model=svdpp)\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MapMovieNameToID()\n",
      "* 1 ran successfully:\n",
      "    - 1 ModelTrain(model=nmf)\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svd': LuigiRunResult(status=<LuigiStatusCode.SUCCESS: (':)', 'there were no failed tasks or missing dependencies')>,worker=<luigi.worker.Worker object at 0x117fdac10>,scheduling_succeeded=True),\n",
       " 'svdpp': LuigiRunResult(status=<LuigiStatusCode.SUCCESS: (':)', 'there were no failed tasks or missing dependencies')>,worker=<luigi.worker.Worker object at 0x12200a520>,scheduling_succeeded=True),\n",
       " 'nmf': LuigiRunResult(status=<LuigiStatusCode.SUCCESS: (':)', 'there were no failed tasks or missing dependencies')>,worker=<luigi.worker.Worker object at 0x117fcce20>,scheduling_succeeded=True)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_param = {\"model\": \"svd\"}\n",
    "svdpp_param = {\"model\": \"svdpp\"}\n",
    "nmf_param = {\"model\": \"nmf\"}\n",
    "\n",
    "flow = d6tflow.WorkflowMulti(ModelTrain, {\"svd\": svd_param, \"svdpp\": svdpp_param, \"nmf\": nmf_param})\n",
    "flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the RMSE score for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8192\n",
      "The RMSE score for svd is: 0.8191501558851487\n",
      "RMSE: 0.8176\n",
      "The RMSE score for svdpp is: 0.8176416440078533\n",
      "RMSE: 0.8982\n",
      "The RMSE score for nmf is: 0.8982009355401239\n"
     ]
    }
   ],
   "source": [
    "rmse_scores = flow.outputLoadMeta()\n",
    "model_score = {}\n",
    "for model in rmse_scores.keys():\n",
    "    model_score[model] = rmse(rmse_scores[model][\"rmse\"])\n",
    "    print(f\"The RMSE score for {model} is:\", model_score[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the model pickle file for each model from the task \"ModelTrain\" and deploy the best one among them (least RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with least RMSE is deployed which is svdpp\n"
     ]
    }
   ],
   "source": [
    "models = flow.outputLoad(task=ModelTrain)\n",
    "deploy_least_rmse_model(models, model_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dd1b8cc75138053aa63d4ac25d986f09bf1a26545663340b9e950210ee010df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
